{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Set up MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Set up MediaPipe drawing utils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Read video file\n",
    "cap = cv2.VideoCapture(\n",
    "    \"/media/shahidul/store1/SD17-V-A10/npy/Abdullah_1.mp4\"\n",
    ")\n",
    "\n",
    "# Define output numpy array\n",
    "output_data = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read frame from video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run face mesh model on frame\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    # Extract face landmarks and add to output data\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = []\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                landmarks.append([landmark.x, landmark.y, landmark.z])\n",
    "        output_data.append(np.array(landmarks))\n",
    "\n",
    "    # Show video frame with face landmarks\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            face_landmarks,\n",
    "            mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=1, circle_radius=1),\n",
    "        )\n",
    "    cv2.imshow(\"FaceMesh\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release video capture and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save output data to numpy array\n",
    "output_data = np.array(output_data)\n",
    "np.save(\"file_face-mesh.npy\", output_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Set up MediaPipe FaceMesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "# Set up MediaPipe drawing utils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Read video file\n",
    "cap = cv2.VideoCapture(\"/media/shahidul/store1/SD17-V-A10/npy/Abdullah_1.mp4\")\n",
    "\n",
    "# Define output numpy array\n",
    "output_data = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read frame from video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run face mesh model on frame\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    # Extract face landmarks and add to output data\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = []\n",
    "        for landmark in results.multi_face_landmarks[0].landmark:\n",
    "            face_landmarks.append([landmark.x, landmark.y, landmark.z])\n",
    "        output_data.append(np.array(face_landmarks))\n",
    "\n",
    "    # Show video frame with face landmarks\n",
    "    if results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.multi_face_landmarks[0],\n",
    "            mp_face_mesh.FACEMESH_LIPS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=1, circle_radius=1),\n",
    "        )\n",
    "    cv2.imshow(\"FaceMesh\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release video capture and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save output data to numpy array\n",
    "output_data = np.array(output_data)\n",
    "np.save(\"file_face-land.npy\", output_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand LandMarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "video_files = \"/media/shahidul/store1/SD17-V-A10/npy/Abdullah_1.mp4\"\n",
    "\n",
    "# Set up MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "\n",
    "# Set up MediaPipe drawing utils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Read video file\n",
    "cap = cv2.VideoCapture(\n",
    "    video_files\n",
    ")\n",
    "\n",
    "# Define output numpy array\n",
    "output_data = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read frame from video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run hand tracking model on frame\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # Extract hand landmarks and add to output data\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = []\n",
    "        for landmark in results.multi_hand_landmarks[0].landmark:\n",
    "            hand_landmarks.append([landmark.x, landmark.y, landmark.z])\n",
    "        output_data.append(np.array(hand_landmarks))\n",
    "\n",
    "    # Show video frame with hand landmarks\n",
    "    if results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.multi_hand_landmarks[0],\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1),\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=1, circle_radius=1),\n",
    "        )\n",
    "    cv2.imwrite(f\"frame_{frame}.jpg\", frame)\n",
    "    cv2.imshow(\"HandTracking\", frame)\n",
    "\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release video capture and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save output data to numpy array\n",
    "output_data = np.array(output_data)\n",
    "file_name = video_files.split(\"/\")[-1]\n",
    "np.save(file_name, output_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Set up video input and output\n",
    "input_file = \"/media/shahidul/store1/SD17-V-A10/npy/Abdullah_1.mp4\"\n",
    "output_file = \"output_video.mp4\"\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_size = (\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    ")\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, frame_size)\n",
    "\n",
    "# Set up Mediapipe hand tracking\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=2)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Process each frame in the input video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB and run Mediapipe hand tracking\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # Draw hand landmarks and connections on frame\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(\n",
    "                    color=(0, 255, 255), thickness=1, circle_radius=1\n",
    "                ),\n",
    "                mp_drawing.DrawingSpec(\n",
    "                    color=(255, 255, 0), thickness=1, circle_radius=1\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    # Write processed frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display processed frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Hand numpy -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Set up video input and output\n",
    "input_file = \"/media/shahidul/store1/SD17-V-A10/npy/Abdullah_1.mp4\"\n",
    "output_file = \"output_video-a.mp4\"\n",
    "landmarks_file = \"hand_landmarks.npy\"\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_size = (\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "    int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    ")\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, frame_size)\n",
    "\n",
    "# Set up Mediapipe hand tracking\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=2)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Store hand landmarks in a list\n",
    "landmarks_list = []\n",
    "\n",
    "# Process each frame in the input video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB and run Mediapipe hand tracking\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    # Draw hand landmarks and connections on frame\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(\n",
    "                    color=(0, 255, 255), thickness=1, circle_radius=1\n",
    "                ),\n",
    "                mp_drawing.DrawingSpec(\n",
    "                    color=(255, 255, 0), thickness=1, circle_radius=1\n",
    "                ),\n",
    "            )\n",
    "            \n",
    "            # Add hand landmarks to list\n",
    "            landmarks_list.append(hand_landmarks.landmark)\n",
    "\n",
    "    # Write processed frame to output video\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Display processed frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Save hand landmarks to Numpy file\n",
    "landmarks_np = np.array(landmarks_list)\n",
    "np.save(landmarks_file, landmarks_np)\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Hand numpy -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Set up Mediapipe hand detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Set up input/output files\n",
    "input_file = '/media/shahidul/store1/SD17-V-A10/npy/Abdullah_1.mp4'\n",
    "output_video_file = 'a.mp4'\n",
    "output_np_file = 'a.mp4.npy'\n",
    "\n",
    "# Open input video file and create output video file\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out_video = cv2.VideoWriter(output_video_file, fourcc, fps, (width, height))\n",
    "\n",
    "# Create empty list to store landmarks\n",
    "landmarks_list = []\n",
    "\n",
    "# Loop through frames in input video\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        # Convert image to RGB for Mediapipe hand detection\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect hands and draw landmarks on image\n",
    "        results = hands.process(image)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Add landmarks to list\n",
    "                landmarks_list.append(hand_landmarks.landmark)\n",
    "        \n",
    "        # Convert image back to BGR for output video\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Write output video frame\n",
    "        out_video.write(image)\n",
    "        \n",
    "        # Display output video frame\n",
    "        cv2.imshow('Output Video', image)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release video files and close window\n",
    "cap.release()\n",
    "out_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert landmarks list to Numpy array and save to file\n",
    "landmarks_np = np.array(landmarks_list)\n",
    "np.save(output_np_file, landmarks_np)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
